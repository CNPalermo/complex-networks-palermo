{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10538add-40a0-477e-aa40-68e88b51eac2",
   "metadata": {},
   "source": [
    "# Esame Ferrara, 22/02/2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "864cb3c9-c03a-4201-b813-b579499e9baa",
   "metadata": {},
   "source": [
    "## Prima domanda: Illustrare lo Small World model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99e81889-e90c-40c7-a25b-e82e1adce4ff",
   "metadata": {},
   "source": [
    "Lo Small World è uno dei quattro newtwork fondamentali che abbiamo studiato, spesso ci si riferisce ad esso con il nome di \"Watts-Strogatz model\", dai suoi creatori.\n",
    "L'idea alla base dello Small World è che si parte da un k-regular network con k strettamente pari, questo non è altro che un network in cui ogni nodo ha degree pari a k, ad esempio un 3-regular network è un network in cui ogni nodo è connesso ad altri 3 nodi.\n",
    "Chiaramente la degree distribution di un simile network è una delta dirac sul valore k.\n",
    "Una volta che si ha il k-regular network si può applicare un processo detto \"rewiring\": Si può immaginare il network come un anello di nodi, si itera su ogni nodo in senso orario (per esempio), e si scrivono i link che ha il nodo i-esimo nel suo verso orario, per ognuno di questi link si estrarrà un numero random float compreso fra 0 e 1, e si comparerà con la cosidettà \"rewiring probability\" p, se il numero estratto è più basso di p il link viene spezzato, e si riconnetterà il nodo con un nodo \"lontano\", dove \"lontano\" significa che non era connesso al nodo originale.\n",
    "Una volta fatto ciò si ottiene uno Small World network.\n",
    "Chiaramente il risultato finale dipende dalla rewiring probability p, se p = 1 il rewiring è totale e non resta nessuna informazione del network k-regular originale (a parte chiaramente il degree medio che resta k e il numero di nodi N), si ottiene un grafico che è a tutti gli effetti una realizzazione di Erdos-Reinyi equivalente ad uno generato - considerando che il k medio resta quello ereditato dal k-regular - con la p (di ER) che è pari generalmente a k/N, dove N è il numero di nodi del network, ereditato chiaramente anch'esso dal k-regular, e k è proprio quello del k-regular.\n",
    "Per rewiring probability più basse abbiamo uno Small World classico, le sue caratteristiche essenziali sono che l'average shortest path lenght è generalmente più basso di un grafico che ad esempio otterremmo applicando un configuration model e ricalcolandolo, da ciò la classica frase \"it's a small world!\" per indicare che l'ASPL fra due nodi è in effetti più basso di un grafico come ER, dove tende a infinito per N che tende a infinito.\n",
    "Si può dire la stessa cosa del Global Clustering Coefficient, questo risulta mediamente più alto di quello che otterremo applicando il configuration model, al contrario di ER dove il CC tende a 0 per N tendente a infinito (si può dimostrare che il CC in un ER va come p, dove con p=1 chiaramente tutti i triangoli sono chiusi, quindi è pari a 1).\n",
    "In generale la degree distribution di uno Small World è pari ad una gaussiana, infatti il k medio si allarga (considerando che si partiva da una delta dirac!), ha quindi un decadimento esponenziale, più simile quindi alla coda di un ER che ad un grafico scale-free come Barabasi_Albert o Borgatti_Everett."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54b9baf5-c657-4b03-8dfa-021ffcdf4987",
   "metadata": {},
   "source": [
    "## Seconda domanda: Illustrare il concetto di percolazione e perché è rilevante in Complex Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90cdfbe0-8d9f-4bf2-8d30-90df55b994d0",
   "metadata": {},
   "source": [
    "Per spiegare la percolazione possiamo immaginare uno strato di roccia bidimenzionale che ha dell'acqua sopra ed una cavità sotto.\n",
    "Se rimuoviamo cerchi di area sempre uguali nella roccia, l'acqua prima o poi riuscirà a passare.\n",
    "Si può scrivere una quantità r chiamata \"order parameter\" che è proprio il rapporto fra il volume (o l'area, in 2D) che è stato \"forato\" e quello totale.\n",
    "Possiamo immaginare un lattice bidimensionale, consideriamo quindi che ogni nodo in questo lattice ha una probabilità p di essere presente o no, quale è la probabilità minima necessaria affinché si può arrivare da un estremo all'altro del lattice?\n",
    "In un lattice 2D questa p_c è pari a circa 0.59.\n",
    "Nello studio dei Complex Network la percolazione è un concetto che ha molte applicazioni, ad esempio con un approccio basato sulla percolazione possiamo chiederci quale sia la probabilità necessaria associata alla presenza di nodi per cui abbiamo una giant component (e siamo quindi in grado, generalmente, di andare da nodo A a nodo B per qualsiasi A e B), utilizzando questo tipo di approccio si trova che la p_c è pari a (<k^2> - 2<k>) / (<k^2> - <k>), ciò deriva dalla condizione di Molloy_Reed in cui <k^2> - 2<k> > 0 , in particolare si può anche indagare sulla vulnerabilità dei network, ad esempio ci si può chiedere: se si rimuovono nodi casualmente con probabilità p, quale è il valore che p deve avere per riuscire a \"rompere\" la giant component? Per un network Scale Free tipo Barabasi Albert viene fuori che p_c è quasi 1, ovvero è praticamente indistruttibile contro attachi random di questo tipo.\n",
    "In effetti per rompere il network sarebbe meglio utilizzare attacchi più strategici, ad esempio attaccando i nodi con alta betweenness.\n",
    "Un approccio legato alla percolazione è anche importante in un network dei contatti che sta alla base di un modello SIR per esempio, la percolazione critica a quel punto è la probabilità che dovremmo usare nel rimuovere casualmente ogni nodo per \"interrompere\" lo spreading di un'epidemia, ovvero può considerarsi ad esempio legata alla frazione di popolazione che bisogna vaccinare."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "962e4f10-8e44-4720-a36f-18959d067308",
   "metadata": {},
   "source": [
    "## Terza domanda: codice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4033ae58-98f8-4377-8bdf-4a3ba2f64292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importiamo qualche utile libreria!\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42707513-032e-4fad-bf52-01cf51c22510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fortunatamente ho già l'edgelist del network degli aereoporti sul pc, chiaramente non pesata e non diretta.\n",
    "\n",
    "g = ig.Graph.Read_Ncol(\"airport_original_edgelist.txt\", names=True, directed=False) #carichiamo il grafico dalla edgelist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1516ea-5cb4-4ec6-8178-302803dc7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig.plot(g, layout=\"graphopt\", vertex_size=5, bbox=(800, 450)) #plottiamo il network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fdc084-90a0-4cdc-bcce-9634eeeb8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendiamoci la giant component:\n",
    "airports_original = g.connected_components().subgraph(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24059ef7-19c0-4335-af0e-c15363c69b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig.plot(airports_original, layout=\"graphopt\", vertex_size=5, bbox=(800, 450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d71cd0-a7cd-482e-af1c-a221b1a035b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scriviamo un codice che ci permetta di fare il configuration model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3379fae-6510-487c-9a04-98e6f1aa3290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_switcher(edgelist):\n",
    "    # mi genero un vettore \"random order\", con l'idea che fa da indice (ogni indice NON si ripete mai) ma in ordine randomico!\n",
    "    random_order = [i for i in range(len(edgelist))]\n",
    "    random.shuffle(random_order)\n",
    "    \n",
    "    for i in range(len(edgelist)):\n",
    "        #mi genero un numero int random casuale che chiaramente farà da indice quindi è compreso fra 0 e len(edgelist)-1\n",
    "        rand = random.randint(0,len(edgelist)-1)\n",
    "        \n",
    "        #mi trovo un link casuale, ad esempio edgelist[randomorder[i]], e li richiamo in modo più leggibile\n",
    "        A_1 = edgelist[random_order[i]][0]\n",
    "        B_1 = edgelist[random_order[i]][1]\n",
    "        \n",
    "        #faccio la stessa cosa però con un link nella posizione rand\n",
    "        A_2 = edgelist[rand][0]\n",
    "        B_2 = edgelist[rand][1]\n",
    "        \n",
    "        \n",
    "        # questi if fanno da controllo, essenzialmente controllano che i link una volta switchati non siano self loops o multi loops, ma invece di andare avanti nel codice e basta, abbasso l'indice i di uno e uscendo dal for posso riprovare a fare lo switch finchè non funziona a dovere (ovvero no self-loops no multi-links), la funzione max serve a fare in modo che se lo switch fallisce proprio all'iterazione 0 non mi ritrovo un indice i negativo!\n",
    "        if A_1 == B_2:\n",
    "            i = max(i-1,0)\n",
    "            continue\n",
    "\n",
    "        if B_1 == A_2 :\n",
    "            i = max(i-1,0)\n",
    "            continue\n",
    "\n",
    "        if (A_1,B_2) in edgelist or (A_2,B_1) in edgelist or (B_2,A_1) in edgelist or (B_1,A_2) in edgelist:\n",
    "            i = max(i-1,0)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #se tutto funziona a dovere, switcho in effetto i link (ovvero se ho A-B e C-D alla fine avrò A-D e C-B)\n",
    "        tuple1 = (A_1, B_2)\n",
    "        tuple2 = (A_2, B_1)\n",
    "        edgelist[random_order[i]] = tuple1\n",
    "        edgelist[rand] = tuple2\n",
    "        \n",
    "        \n",
    "    return edgelist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c81cb-c599-44e1-b286-e4f39d0e2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per applicare il configuration model ci serve l'edgelist del network, prendiamocela\n",
    "\n",
    "edgelist = airports_original.get_edgelist() #chiaramente prendiamo l'edgelist della giant component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd36bc6-83fe-48e1-b4d5-dc027bc277c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adesso scriviamo un ciclo for che ci realizza n realizzazioni del configuration model!\n",
    "\n",
    "nr = 10 # vogliamo 100 realizzazioni\n",
    "random_edgelist_vector = [0] * nr # inizializziamo la lista lunga nr\n",
    "\n",
    "for i in range(nr):\n",
    "    random_edgelist_vector[i] = edge_switcher(edgelist)\n",
    "    \n",
    "# il ciclo for sopra potrebbe metterci un po' ad eseguire, il tempo scala linearmente con nr, per nr = 1 ci mette circa 6 secondi, quindi con nr = 100 ci metterà circa 10 minuti sul mio portatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26f78a-12bc-4c54-861c-c6be4754505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardiamo un network a caso di quelli generati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb6484-63d9-44f3-92dd-55f17a2c4d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6 # cambiare questo indice per vedere grafici diversi!\n",
    "\n",
    "g = ig.Graph(random_edgelist_vector[index], directed = False)\n",
    "ig.plot(g, layout=\"graphopt\", vertex_size=5, bbox=(800, 450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e33eb5-eb0c-4d11-9e1d-a3ad8b49e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adesso calcoliamoci una partition del network originale usando la modularity\n",
    "\n",
    "community_original = airports_original.community_multilevel() # questo algoritmo dovrebbe basarsi sull'argoritmo di Blondel che massimizza la modularità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aaf5d8-0a2b-4d8e-ba16-c6fecb163bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plottiamo la partizione del network originale\n",
    "ig.plot(community_original, layout=\"graphopt\", vertex_size=5, bbox=(800, 450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b98ab3-8cf0-4953-809d-e50c604eb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creiamo un for loop per caricare su igraph ognuna di queste partizioni\n",
    "\n",
    "airports_switched_vector = [0] * nr\n",
    "\n",
    "for i in range(nr):\n",
    "    airports_switched_vector[i] = ig.Graph(random_edgelist_vector[i], directed = False) #è una lista di grafici igraph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42336f7b-43b2-42bd-a37a-a162a961e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creiamo un for loop per calcolarci le 100 partitions dei 100 networks utilizzando lo stesso algoritmo\n",
    "\n",
    "community_switched_vector = [0] * nr\n",
    "\n",
    "for i in range(nr):\n",
    "    community_switched_vector[i] = airports_switched_vector[i].community_multilevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b93ee-9f1c-4ab9-87f5-8c876b923ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plottiamo la partizione di un network del configuration model a caso\n",
    "index = 7 # cambiare qui per vedere partizioni diverse!\n",
    "\n",
    "ig.plot(community_switched_vector[index], layout=\"graphopt\", vertex_size=5, bbox=(800, 450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e2b0b-e63a-4eaa-9a23-493a263603a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per testare il codice, calcoliamoci l'ARI fra la partizione originale del network e... se stessa\n",
    "\n",
    "ARI = ig.compare_communities(community_original, community_original, method=\"adjusted_rand\")\n",
    "print(ARI) #dovrebbe fare 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8129a6cb-438b-44d9-919e-3146fd691d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adesso calcoliamo l'ARI fra le partizioni trovate e quello originale, chiaramente avremo un vettore di ARI\n",
    "\n",
    "ARI_vector = [0] * nr\n",
    "\n",
    "for i in range(nr):\n",
    "    ARI_vector[i] = ig.compare_communities(community_original, community_switched_vector[i], method=\"adjusted_rand\") #compute the ARI between 2 communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403d534-ec83-4beb-ab9c-450ee47c03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARI_np = np.array(ARI_vector) #first use of numpy in the code!!!\n",
    "\n",
    "ARI_mean = np.mean(ARI_np)\n",
    "ARI_std = np.std(ARI_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8935a42-68d4-4a56-bdea-06058fcea80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"L'ARI medio risulta: {}. La sua deviazione standard è pari a: {}\".format(ARI_mean, ARI_std))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "732e2763-af9d-48f6-9772-3eb45b78c13c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Chiaramente l'ARI medio è praticamente nullo, considerando che le partizioni effettuate sulle varie realizzazioni del configuration model non c'entrano niente con quella originale."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "859e43f7-685e-44d8-97b6-e295961e03a2",
   "metadata": {},
   "source": [
    "L'RI atteso, anche scritto E[RI] è il valore medio atteso dell'RI (Rand Index) trovato su N molto grande di realizzazioni di partizioni randomiche (ad esempio usando il configuration model, proprio come fatto qui). L'ARI in generale si definisce come (RI-E[RI]) / (max(RI) - E[RI]), e si può dimostrare come l'ARI si può poi scrivere in funzione di a,b,c,d che sono, rispettivamente (frazioni di nodi nelle stesse community in part1 e part2, frazioni di nodi in stessa community in part1 ma non in part2, frazioni di nodi nella stessa community in part2 ma non in part1, e frazioni di nodi che non sono nella stessa community sia in part1 che part2)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3ef7ff7-58c1-4346-96e0-afa0611ec2fb",
   "metadata": {},
   "source": [
    "L'E[ARI] che abbiamo calcolato in questo caso, è supposto che faccia 0, serve come \"baseline\" per valutare l'ARI ottenuto invece fra due partizioni differenti ma non casuali"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}